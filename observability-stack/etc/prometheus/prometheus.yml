global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).
  external_labels:
    server_name: prometheus

#Alertmanager configuration
alerting:
  alertmanagers:
  - scheme: https
    basic_auth:
      username: $observ_user
      password: $observ_passw
    tls_config: 
      ca_file: /etc/ssl/tls_prometheus_crt.crt
      insecure_skip_verify: true
  - static_configs:
    - targets:
      - localhost:9093

rule_files:
#  - "/etc/alertmanager/rules.yml"
#  - "second_rules.yml"

scrape_configs:
  - job_name: 'discovered'
    file_sd_configs:
      - files: ['/etc/prometheus/discovered/*.yml']
  - job_name: prometheus
    scheme: https
    basic_auth:
      username: $observ_user
      password: $observ_passw
    tls_config: 
      ca_file: /etc/ssl/tls_prometheus_crt.crt
      insecure_skip_verify: true
    static_configs:
      - targets:
        - localhost:9090 #put you remote server here
  - job_name: node_exporter
    metrics_path: /metrics
    scheme: https
    enable_compression: true
    basic_auth:
      username: $observ_user
      password: $observ_passw
    tls_config:
      ca_file: /etc/ssl/tls_prometheus_crt.crt
      insecure_skip_verify: true
    follow_redirects: true
    enable_http2: true
    static_configs:
      - targets:
        - localhost:9100 #put you remote server here
  - job_name: docker
    static_configs:
      - targets:
        - localhost:9090 #put you remote server here
#   - job_name: node_exporter_multi_node
#     static_configs:
# {% for n in range(3400) %}
#       - targets: ['host-node-{{n}}:9100']
#         labels:
#           host_number: cfg_{{n}}
#           role: node-exporter
#           env: prod
# {% endfor %}